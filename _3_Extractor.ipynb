{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will build the Extractor model for Pennyworth. This model is responsible for extracting category, category type and attributes from an article of clothings that were selected in the previous balancing step. Once the model achieves sufficient accuracy in predicting the above qualities, we will be using the Extractor-derived layer activations to construct a meaningful and rich description of clothing items. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from packages import *\n",
    "import numpy as np, matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.utils import shuffle, class_weight\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "import time\n",
    "from PIL import Image\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from ipywidgets import IntProgress, Label\n",
    "from tensorflow.data.experimental import AUTOTUNE\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = 'float32' # aimed to use float16 but ran in to 1000's of issues with Keras and Tensorflow\n",
    "epsilon = 1e-4 if fp == 'float32' else 1e-7\n",
    "tf.config.gpu.set_per_process_memory_growth(True) # Needed this per a bug\n",
    "tf.config.gpu.set_per_process_memory_fraction(.9)\n",
    "tf.keras.backend.set_floatx(fp)\n",
    "tf.keras.backend.set_epsilon(epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the Tensorflow Dataset API to construct the dataset and preprocess the images on the fly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "input_shape = (300, 300, 3)\n",
    "shuffle_buffer_size = batch_size*4\n",
    "prefetch_buffer_size = 2\n",
    "repeat = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition = load_pickle(os.path.join(LINK_DIR, 'partition_balanced.pkl'))\n",
    "img_cat = load_pickle(os.path.join(LINK_DIR, 'img_cat_balanced.pkl'))\n",
    "img_attr = load_pickle(os.path.join(LINK_DIR, 'img_attr_balanced.pkl'))\n",
    "cat_str = load_pickle(os.path.join(LINK_DIR, 'cat_str_balanced.pkl'))\n",
    "attr_str = load_pickle(os.path.join(LINK_DIR, 'attr_str_balanced.pkl'))\n",
    "\n",
    "# cat_types = load_pickle(os.path.join(LINK_DIR, 'cat_types.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition['train'] = shuffle(partition['train'])\n",
    "partition['val'] = shuffle(partition['val'])\n",
    "partition['test'] = shuffle(partition['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'train':{}, 'val': {}, 'test': {}}\n",
    "N = {'train': 0, 'val': 0, 'test': 0}           \n",
    "for split in data: data[split] = {'path': [], 'cat':[], 'attr': []}\n",
    "for split in partition:\n",
    "    for path in partition[split]:\n",
    "        N[split]+=1\n",
    "        data[split]['cat'].append(img_cat[path])\n",
    "        data[split]['attr'].append(img_attr[path])\n",
    "        data[split]['path'].append(os.path.join(IMG_DIR, path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 72008, 'val': 9001, 'test': 9001}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert N['train'] > 3 * N['val'] + 3 * N['test']\n",
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_datasets = {}\n",
    "for split in data:\n",
    "    tensor_datasets[split] = {}\n",
    "    for key in data[split]:\n",
    "        tensor_datasets[split][key] = tf.data.Dataset.from_tensor_slices(data[split][key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def color(image):\n",
    "    image = tf.image.random_hue(image, 0.08)\n",
    "    image = tf.image.random_saturation(image, 0.8, 1.2)\n",
    "    image = tf.image.random_brightness(image, 0.04)\n",
    "    image = tf.image.random_contrast(image, 0.8, 1.1)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def flip(image):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def load_and_preprocess(path):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "#     image = tf.keras.applications.vgg16.preprocess_input(image)\n",
    "    image /= 255\n",
    "    image -= 0.5\n",
    "    image *= 2.\n",
    "    image = tf.image.resize_with_pad(image, input_shape[0], input_shape[1], antialias=True)\n",
    "    if fp == 'float16':\n",
    "        image = tf.cast(image, tf.float16)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "augmentations = [flip, color]\n",
    "for split in tensor_datasets:\n",
    "    loaded_preprocessed_images =  tensor_datasets[split]['path'].map(load_and_preprocess, \n",
    "                                                               num_parallel_calls=AUTOTUNE)  \n",
    "\n",
    "    datasets[split] = tf.data.Dataset.zip((loaded_preprocessed_images, \n",
    "                                       (tensor_datasets[split]['cat'],\n",
    "                                       tensor_datasets[split]['attr'])))\n",
    "    \n",
    "                                                                     \n",
    "    datasets[split] = tf.data.Dataset.map(datasets[split], lambda x, y:  (x, {'cat_classifier': y[0], \n",
    "                                                                              'attr_classifier': y[1]}))\n",
    "datasets['train'] = tf.data.Dataset.repeat(datasets['train'], repeat)\n",
    "\n",
    "for aug in augmentations:\n",
    "    datasets['train'] = datasets['train'].map(lambda x, y: (aug(x), y) , num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "for split in datasets:\n",
    "    datasets[split] = datasets[split].shuffle(buffer_size=shuffle_buffer_size)\n",
    "    datasets[split] =  datasets[split].batch(batch_size=batch_size)\n",
    "    datasets[split] = datasets[split].prefetch(buffer_size=prefetch_buffer_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in datasets['train']:\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG\n",
    "We will be applying transfer learning using the VGG16 pretrained model. However, we will only use up to block5 and train the last block for our task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = '/home/kaan/.keras/models/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vgg_base(input_shape, weigths_path, block5):\n",
    "    \n",
    "    model = tf.keras.Sequential(name='vgg_base')\n",
    "    model.add(InputLayer(input_shape=input_shape))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', name='block1_conv1', padding='same'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', name='block1_conv2', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool'))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', name='block2_conv1', padding='same'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', name='block2_conv2', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool'))\n",
    "\n",
    "    model.add(Conv2D(256,(3, 3), activation='relu', name='block3_conv1', padding='same'))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', name='block3_conv2', padding='same'))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', name='block3_conv3', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool'))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', name='block4_conv1', padding='same'))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', name='block4_conv2', padding='same'))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', name='block4_conv3', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool'))\n",
    "\n",
    "    if block5:\n",
    "        model.add(Conv2D(512, (3, 3), activation='relu', name='block5_conv1', padding='same'))\n",
    "        model.add(Conv2D(512, (3, 3), activation='relu', name='block5_conv2', padding='same'))\n",
    "        model.add(Conv2D(512, (3, 3), activation='relu', name='block5_conv3', padding='same'))\n",
    "        model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool'))\n",
    "\n",
    "    f = h5py.File(weights_path)\n",
    "    for layer in model.layers:\n",
    "        if 'conv' in layer.name:\n",
    "            weights = [f[layer.name][w] for w in f[layer.name].attrs['weight_names']]\n",
    "            layer.set_weights(weights)\n",
    "    f.close()\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_block(input_shape, name, dropout_rate, pool_type='max'):\n",
    "    \n",
    "    model = tf.keras.Sequential(name=name)\n",
    "    model.add(InputLayer(input_shape=input_shape))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', name='block1_conv1', padding='same'))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', name='block1_conv2', padding='same'))\n",
    "    if pool_type == 'max':\n",
    "        model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool'))\n",
    "    elif pool_type =='avg':\n",
    "        model.add(AveragePooling2D((2, 2), strides=(2, 2), name='block1_pool'))\n",
    "    model.add(Flatten())\n",
    "    if dropout_rate:\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extractor\n",
    "With the VGG base model and the `build_block` helper in place, we can begin building our Extractor model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Extractor:\n",
    "    def build(input_shape = input_shape, block5 = False, weights_path=weights_path, cat_units=len(cat_str), attr_units=len(attr_str)):\n",
    "        inputs = Input(input_shape, name='image_input')\n",
    "        vgg_base = build_vgg_base(input_shape, weights_path, block5=block5)\n",
    "        vgg_base.trainable=False\n",
    "        post_vgg = vgg_base(inputs)\n",
    "        \n",
    "        cat = build_block(vgg_base.output_shape[1:], 'cat', .2)(post_vgg)\n",
    "        cat = Dense(4096, activation='relu', name='cat_dense')(cat)\n",
    "#         cat = Dropout(rate=.1,  name='cat_dropout')(cat)\n",
    "        cat = Dense(cat_units, activation='softmax', name='cat_classifier')(cat)\n",
    "        \n",
    "        attr =  build_block(vgg_base.output_shape[1:], 'attr', .2)(post_vgg)\n",
    "        attr = Concatenate(name='concat_attr')([attr, cat])\n",
    "        attr = Dense(4096, activation='relu', name='attr_dense')(attr)\n",
    "#         attr = Dropout(rate=.1, name='attr_dropout')(attr)\n",
    "        attr = Dense(attr_units, activation='sigmoid', name='attr_classifier')(attr)\n",
    "        return tf.keras.models.Model(inputs=inputs, outputs={'cat_classifier': cat,\n",
    "                                                             'attr_classifier': attr}, name='Extractor')\n",
    "    \n",
    "    @tf.function\n",
    "    def loss_fn(truth, logits):\n",
    "        cat_loss = tf.keras.losses.sparse_categorical_crossentropy(truth[0], logits['cat_classifier'])\n",
    "        cat_type_loss = tf.keras.losses.sparse_categorical_crossentropy(truth[1], logits['cat_type_classifier'])\n",
    "        attr_loss = tf.keras.losses.binary_crossentropy(truth[2], logits['attr_classifier'])\n",
    "        return {'cat_classifier': cat_loss, 'cat_type_classifier': cat_type_loss, 'attr_classifier': attr_loss}\n",
    "    \n",
    "    def loss_to_string(loss):\n",
    "        loss_numpy = (tf.reduce_mean(loss['cat_classifier']).numpy(), tf.reduce_mean(loss['cat_type_classifier']).numpy(), \n",
    "                      tf.reduce_mean(loss['attr_classifier']).numpy())\n",
    "        string = 'Category loss: {:.2e}, Category type loss: {:.2e}, Attribute loss: {:.2e}'.format(*loss_numpy)\n",
    "        return string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_weights = class_weight.compute_class_weight('balanced', np.arange(len(cat_str)) ,list(img_cat.values()))\n",
    "Y = np.array(list(img_attr.values()))\n",
    "attr_weights = np.array([class_weight.compute_class_weight('balanced', [0, 1],  Y[:, i]) for i in range(len(attr_str))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weighted_loss(weights):\n",
    "    @tf.function\n",
    "    def weighted_loss(y_true, y_pred):\n",
    "        y_true_float = tf.cast(y_true, tf.float32)\n",
    "        return tf.keras.backend.mean( \n",
    "            (weights[:,0]**(1-y_true_float))*(weights[:,1]**(y_true_float))*tf.keras.backend.binary_crossentropy(y_true_float, y_pred)\n",
    "            , axis=-1)\n",
    "    return weighted_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = Extractor.build(block5=True)\n",
    "extractor.compile(optimizer=tf.keras.optimizers.Adam(), \n",
    "                  loss={'cat_classifier': 'sparse_categorical_crossentropy', \n",
    "                        'attr_classifier': get_weighted_loss(attr_weights)},\n",
    "                  loss_weights={'cat_classifier': cat_weights},\n",
    "                  metrics= {'cat_classifier': ['accuracy'], \n",
    "                            'attr_classifier': [tf.keras.metrics.Recall(name='recall'), tf.keras.metrics.Precision(name='precision')]})\n",
    "log_dir = os.path.join(SRC_DIR, 'logs', '{}'.format(datetime.fromtimestamp(time.time()).strftime('%H-%M-%S_%Y-%m-%d')))\n",
    "tb = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True, update_freq='batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Extractor\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "image_input (InputLayer)        [(None, 300, 300, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg_base (Sequential)           (None, 9, 9, 512)    14714688    image_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "cat (Sequential)                (None, 8192)         4719616     vgg_base[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "cat_dense (Dense)               (None, 4096)         33558528    cat[1][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "attr (Sequential)               (None, 8192)         4719616     vgg_base[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "cat_classifier (Dense)          (None, 12)           49164       cat_dense[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concat_attr (Concatenate)       (None, 8204)         0           attr[1][0]                       \n",
      "                                                                 cat_classifier[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "attr_dense (Dense)              (None, 4096)         33607680    concat_attr[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attr_classifier (Dense)         (None, 32)           131104      attr_dense[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 91,500,396\n",
      "Trainable params: 76,785,708\n",
      "Non-trainable params: 14,714,688\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "extractor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4500"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_batches = repeat * N['train'] // batch_size\n",
    "num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "249/450 [===============>..............] - ETA: 1:27 - loss: 4.1619 - attr_classifier_loss: 0.6739 - cat_classifier_loss: 1.9747 - attr_classifier_recall: 0.6256 - attr_classifier_precision: 0.0734 - cat_classifier_accuracy: 0.4131"
     ]
    }
   ],
   "source": [
    "extractor.fit_generator(datasets['train'].take(num_batches//10), \n",
    "                                               epochs=10, callbacks=[tb], validation_data=datasets['val'], validation_steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor.save(os.path.join(MODEL_DIR, 'extractor.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activations\n",
    "Now we will extract activations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = partition['train'] + partition['val'] + partition['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = [os.path.join(IMG_DIR, f) for f in all_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = tf.data.Dataset.from_tensor_slices(all_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = all_files.map(load_and_preprocess, num_parallel_calls=AUTOTUNE)\n",
    "all_images = all_images.batch(batch_size=batch_size)\n",
    "all_images = all_images.prefetch(buffer_size=prefetch_buffer_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 4096)"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extractor.layers[-6].output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_layer_output = tf.keras.backend.function([extractor.layers[0].input],\n",
    "                                  [extractor.layers[-6].output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = []\n",
    "for img in all_images:\n",
    "    activations.append(get_layer_output([img])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = np.concatenate((np.array(activations[:-1]).reshape((len(activations)-1)*activations[0].shape[0], \n",
    "                                     activations[0].shape[1]), activations[-1] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(ACTIVATIONS_DIR, 'activations_cat.npy'), activations, allow_pickle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [10.0, 10.0]\n",
    "fig, ax = plt.subplots()\n",
    "_ = ax.matshow(y['attr_classifier'].numpy()[:32])\n",
    "_ = ax.set_xticks(np.arange(32))\n",
    "_ = ax.set_xlabel('Attributes')\n",
    "_ = ax.set_ylabel('Examples')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pennyworth_3.6",
   "language": "python",
   "name": "pennyworth_3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
